api

{'spark.aispeech.queryName':'kf_api_detail_realtime',
'spark.job.log.level':'WARN',
'spark.aispeech.job.source':'kafka',
'spark.aispeech.job.sink':'es',
'spark.aispeech.read.kafka.topics':'ba-prod-trace-log',
'spark.aispeech.read.kafka.startOffsets':'latest',
'spark.aispeech.read.kafka.brokers':'10.24.1.10:6667,10.24.1.21:6667,10.24.1.32:6667,10.24.1.43:6667',
'spark.aispeech.read.kafka.failOnDataLoss':'false',
'spark.aispeech.read.kafka.maxOffsetsPerTrigger':'10000',
'spark.aispeech.write.es.nodes.wan.only':'false',
'spark.aispeech.write.es.nodes':'10.24.1.44,10.24.1.23,10.24.1.24',
'spark.aispeech.write.es.port':'9200',
'spark.aispeech.write.es.batch.size.bytes':'1mb',
'spark.aispeech.write.es.batch.size.entries':'2000',
'spark.aispeech.write.es.batch.write.refresh':'false',
'spark.aispeech.write.es.batch.write.retry.wait':'30s',
'spark.aispeech.write.es.batch.write.retry.count':'6',
'spark.aispeech.write.es.type':'summary',
'spark.aispeech.write.es.index':'ba_kf_api_detail-',
'spark.es.net.http.auth.user':'rsbj_ba_backend',
'spark.es.net.http.auth.pass':'ba_backend@Speech1024',
'spark.aispeech.checkpoint':'hdfs://insight/user/rsbj_ba_backend/business/',
'spark.aispeech.trigger.time':'1 seconds',
'spark.monitor.urls':'https://oapi.dingtalk.com/robot/send?access_token=0c44f10f6b0a02b06838010851293c2b8c61cb4e2e3849bcbb395172e72988a2',
'spark.memory.fraction':'0.70',
'spark.memory.storageFraction':'0.30',
'spark.driver.userClassPathFirst':'true',
'spark.executor.userClassPathFirst':'true',
'spark.yarn.driver.memoryOverhead':'1024mb',
'spark.yarn.executor.memoryOverhead':'1024mb',
'spark.cleaner.periodicGC.interval':'10min',
'spark.sql.shuffle.partitions':'3', 
'spark.network.timeout':'300s',
'spark.driver.extraJavaOptions':'-XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+ParallelRefProcEnabled -XX:+CMSClassUnloadingEnabled',
'spark.executor.extraJavaOptions':'-XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+ParallelRefProcEnabled -XX:+CMSClassUnloadingEnabled',
'spark.serializer':'org.apache.spark.serializer.KryoSerializer',
'spark.kryo.referenceTracking':'false',
'spark.scheduler.listenerbus.eventqueue.size':'100000'}