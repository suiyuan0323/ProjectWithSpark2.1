{'spark.aispeech.job.master':'yarn',
'spark.job.log.level':'WARN',
'spark.aispeech.job.source':'kafka',
'spark.aispeech.job.sink':'es',
'spark.aispeech.queryName':'log_error_1m_realTime',
'spark.aispeech.checkpoint':'hdfs://insight/user/rsbj_ba_backend/business/',
'spark.aispeech.read.kafka.brokers':'10.24.1.10:6667,10.24.1.21:6667,10.24.1.32:6667,10.24.1.43:6667',
'spark.aispeech.read.kafka.maxOffsetsPerTrigger':'2000000',
'spark.aispeech.read.kafka.topics':'ba-prod-trace-log',
'spark.aispeech.read.kafka.failOnDataLoss':'false',
'spark.aispeech.read.kafka.startOffsets':'latest',
'spark.aispeech.write.es.nodes.wan.only':'false',
'spark.aispeech.write.es.nodes':'10.24.1.44,10.24.1.23,10.24.1.24',
'spark.aispeech.write.es.port':'9200',
'spark.aispeech.write.es.batch.size.bytes':'2mb',
'spark.aispeech.write.es.batch.size.entries':'5000',
'spark.aispeech.write.es.batch.write.refresh':'false',
'spark.aispeech.write.es.batch.write.retry.wait':'30s',
'spark.aispeech.write.es.batch.write.retry.count':'3',
'spark.aispeech.write.es.type':'summary',
'spark.aispeech.write.es.index':'log_error_1m-',
'spark.es.net.http.auth.user':'rsbj_ba_backend',
'spark.es.net.http.auth.pass':'ba_backend@Speech1024',
'spark.aispeech.data.error.code':'500,400',
'spark.aispeech.data.agg.duration.time':'1 minutes',
'spark.aispeech.data.watermark.delay':'60 seconds',
'spark.aispeech.trigger.time':'60 seconds',
'spark.memory.fraction':'0.8',
'spark.memory.storageFraction':'0.2',
'spark.memory.offHeap.enabled':'true',
'spark.memory.offHeap.size':'2048mb',
'spark.yarn.driver.memoryOverhead':'1024mb',
'spark.yarn.executor.memoryOverhead':'1024mb',
'spark.cleaner.periodicGC.interval':'15min',
'spark.monitor.urls':'https://oapi.dingtalk.com/robot/send?access_token=0c44f10f6b0a02b06838010851293c2b8c61cb4e2e3849bcbb395172e72988a2',
'spark.driver.extraJavaOptions':'-XX:+UseG1GC -XX:+UseCompressedOops -Xms2000M -Xmn400M',
'spark.executor.extraJavaOptions':'-XX:+UseG1GC -XX:+UseCompressedOops -Xms2000M -Xmn400M',
'spark.serializer':'org.apache.spark.serializer.KryoSerializer',
'spark.sql.shuffle.partitions':'50'}